{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotiscience as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with authorization keys\n",
    "CREDENTIALS = {}\n",
    "CREDENTIALS['client_id'] = client_id\n",
    "CREDENTIALS['client_secret'] = client_secret\n",
    "CREDENTIALS['redirect_url'] = redirect_url\n",
    "CREDENTIALS['user_id'] = userid\n",
    "CREDENTIALS['genius_access_token'] = genius_access_token # genius is optional, only\n",
    "\n",
    "\"\"\"You also can set your credentials id on credentials.py and import from spotiscience\"\"\"\n",
    "\n",
    "# returns 'downloader class'\n",
    "sd = sps.downloader.SpotiScienceDownloader(credentials=CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playlist download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return song features of playlist\n",
    "len_playlist=50\n",
    "playlist = \"\" # playlist id\n",
    "playlist_data = sd.get_playlist_song_features(playlist_id=playlist,n_songs=len_playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = playlist_data['fusion'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut obtenir des informations des artistes directement\n",
    "# problème : demande à chaque fois l'autorisation so meh for automatisation\n",
    "artist = 'metallica'\n",
    "sd.get_artist_information(artist=artist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction : mood and topics, examples on one song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns 'predicter class'\n",
    "sp = sps.SpotiSciencePredicter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the tag of mood \n",
    "mood = sp.predict_song_mood(song=song)\n",
    "song['mood'] = mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Song Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = sd.get_song_music_genre(song_id=song['id'])\n",
    "song['genre'] = genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics topics prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = sd.get_song_lyrics(songname=song['name'],artistname=song['artist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic prediction of song lyrics uses any of the algorithms Latent Dirichlet Allocation Model (LDA), Non Negative Matrix Factorization Model (NMF) or Latent Semantic Indexing Model (LSI). To do this, I based my code on the following article which you can read here.\n",
    "\n",
    "To predict the topic of lyrics you must configure the following parameters:\n",
    "\n",
    "lyric = the lyric of the song\n",
    "\n",
    "model = the model to use [options are “lsi”,”lda” or “nmf”]\n",
    "\n",
    "lang = language of the song lyric [options are “english” or “spanish”]\n",
    "\n",
    "n_grams = number of subsence of words to group\n",
    "\n",
    "n_topics = number of returned topics\n",
    "\n",
    "top_n = number of words per returned topic\n",
    "\n",
    "For more information about the parameter n_grams, you can read the official documentation about vectorization with sklearn by clicking here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recognize language and topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a necessity to add errors handling for topics : not every song has lyrics avaible, nor every lyrics is in french, english, spanish or german."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'en' : 'english',\n",
    "    'fr' : 'french',\n",
    "    'es': 'spanish',\n",
    "    'de': 'german'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = sd.get_song_lyrics(songname=song['name'],artistname=song['artist'])\n",
    "model = 'lda' # (available type 'lda', 'lsi', 'nmf')\n",
    "lang = languages[detect(lyrics)] # (available type 'english','spanish', 'french', 'german')\n",
    "# check for the last one.\n",
    "# using langdetect detect function to identify the language\n",
    "# need to had a error gestion regarding the language, if the lyrics can't be identify in those\n",
    "# or install the core relevant to the language\n",
    "n_grams = (1,1)\n",
    "n_topics = 1\n",
    "top_n = 5\n",
    "topics = sp.predict_topic_lyric(lyrics,model,lang,n_grams,n_topics,top_n)\n",
    "song['topics'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_topic=[]\n",
    "for nb in topics:\n",
    "    for topic in topics[nb][0]:\n",
    "        list_topic.append(topic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = sps.SpotiSciencePredicter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'en' : 'english',\n",
    "    'fr' : 'french',\n",
    "    'es': 'spanish',\n",
    "    'de': 'german'\n",
    "}\n",
    "name = 'fusion' # name of the playlist u want to extract the predictions from\n",
    "len_playlist = 654 #828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return song features of playlist\n",
    "playlist_data = sd.get_playlist_song_features(playlist_id=playlist,n_songs=len_playlist)\n",
    "playlist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song in playlist_data[name]:\n",
    "\n",
    "    mood = sp.predict_song_mood(song=song)\n",
    "    song['mood'] = str(mood)\n",
    "\n",
    "    genre = sd.get_song_music_genre(song_id=song['id'])\n",
    "    song['genre'] = genre\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = sps.downloader.SpotiScienceDownloader(credentials=CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(playlist_data[name])):\n",
    "    #create error : juste relaunch it at the same place it stops\n",
    "    #linked to get_feature_name\n",
    "    song = playlist_data[name][i]\n",
    "    try:\n",
    "        lyrics = sd.get_song_lyrics(songname=song['name'],artistname=song['artist'])\n",
    "    except (TimeoutError, ConnectionError, ConnectionAbortedError, ConnectionRefusedError, Exception) as e:\n",
    "        print(e, song['name'],\" we set it has no lyrics\")\n",
    "        lyrics = ''\n",
    "    if lyrics == '':\n",
    "        song['has_lyrics'] = False\n",
    "        song['topics'] = []\n",
    "    else:\n",
    "        song['has_lyrics'] = True\n",
    "        model = 'lda' # (available type 'lda', 'lsi', 'nmf')\n",
    "        lang = detect(lyrics)\n",
    "        if not lang in languages.keys():\n",
    "            #language of the song not yet supported, feel free to add it\n",
    "            song['topics'] = []\n",
    "        else:\n",
    "            lang = languages[lang] # (available type 'english','spanish', 'french', 'german')\n",
    "        \n",
    "            # check for the last one.\n",
    "            # using langdetect detect function to identify the language\n",
    "            # need to had a error gestion regarding the language, if the lyrics can't be identify in those\n",
    "            # or install the core relevant to the language\n",
    "            #default parameter\n",
    "            n_grams = (1,1)\n",
    "            n_topics = 1\n",
    "            top_n = 5\n",
    "            try:\n",
    "                topics = sp.predict_topic_lyric(lyrics,model,lang,n_grams,n_topics,top_n)\n",
    "                list_topic=[]\n",
    "                for nb in topics:\n",
    "                    for topic in topics[nb][0]:\n",
    "                        list_topic.append(topic[0])\n",
    "                song['topics'] = list_topic\n",
    "            except AttributeError as e:\n",
    "                print(e, \"set to no topics\")\n",
    "                song['topics'] = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist = pd.DataFrame.from_records(playlist_data[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nb tracks : \", len(df_playlist['topics']), \"Number of tracks missing topics due to timeout :\",len(df_playlist[[len(t)==0 for t in df_playlist['topics']]]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_genre = df_playlist['genre'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_size_inches(10,60)\n",
    "pd.Series(collected_genre).value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retient en genre les suivants :\n",
    "- jazz ou funk\n",
    "- pop\n",
    "- electro ou techno ou club ou tronica\n",
    "- synth\n",
    "- rock\n",
    "- prog ou exp\n",
    "- alt\n",
    "- dance, rave\n",
    "- rap\n",
    "- ind for indie ou indé (in french)\n",
    "- franc (français, france), french\n",
    "- hip hop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfdefined_genre = ['jazz,funk','pop','electro,tronica','techno,club','house','synth,dream',\n",
    "'rock','prog,exp','alt,modern','dance,rave','rap','franc, french','ind','hip,hop','metal']\n",
    "for genre in selfdefined_genre:\n",
    "    df_playlist[genre] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identification of the song 49 (50th) to the chosen genres\n",
    "song = df_playlist.iloc[49]\n",
    "for genre in selfdefined_genre:\n",
    "    subgenre = genre.split(',')\n",
    "    b = False\n",
    "    for sub in subgenre:\n",
    "        for song_genre in song['genre']:\n",
    "            b = b or (sub in song_genre) #we test if in the str of the genre of the song we find an occurence of our subgenre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identification for every song\n",
    "for genre in selfdefined_genre:\n",
    "    rows_in_genre = []\n",
    "    for song_genre in df_playlist['genre']:\n",
    "        subgenre = genre.split(',')\n",
    "        b = False\n",
    "        for sub in subgenre:\n",
    "            for song_subgenre in song_genre:\n",
    "                b = b or (sub in song_subgenre) #we test if in the str of the genre of the song we find an occurence of our subgenre\n",
    "        rows_in_genre.append(b)\n",
    "    df_playlist[genre] = rows_in_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist.to_pickle(\"fusion_with_mood_genre_lyrics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numvar = ['popularity', 'length',\n",
    "       'acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "       'liveness', 'valence', 'loudness', 'speechiness', 'tempo']\n",
    "categorical_var = ['mood','artist']+selfdefined_genre\n",
    "list_var = ['genre','topics']\n",
    "df_clustering = df_playlist[numvar+categorical_var+list_var]\n",
    "# a question can be ask about popularity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Only Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering[numvar].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "j=0\n",
    "for i in [5,6,7,8]:#[3, 4, 6, 10]:\n",
    "    j += 1\n",
    "    '''\n",
    "    Create KMeans instance for different number of clusters\n",
    "    '''\n",
    "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(j, 2)\n",
    "    '''\n",
    "    Create SilhouetteVisualizer instance with KMeans instance\n",
    "    Fit the visualizer\n",
    "    '''\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    ax[q-1][mod].set_title(\"k = \" + str(i))\n",
    "    visualizer.fit(df_clustering[numvar])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric and Categorical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we made a lot of work to predic a mood and some genre, we must try to use those categorical variables, which we can't do with K-Means.\n",
    "So first I based the following code on [Jorge Martin Lasaosa post](https://towardsdatascience.com/clustering-on-numerical-and-categorical-features-6e0ebcf1cbad) about Gower Distance, check it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gower distance $ ps_{ij}^{(f)} $ between $i$ and $j$ for the variable $f$ is : \n",
    "- for a numeric type : $ ps_{ij}^{(f)} = 1 - |x_{if}-x_{jf}|/R_{f} $ avec $ R_f = \\max f - \\min f $\n",
    "- For a categorical feature, the partial similarity between two individuals is one only when both observations have exactly the same value for this feature. Zero otherwise.\n",
    "\n",
    "Code inspired by this [post](https://www.thinkdatascience.com/post/2019-12-16-introducing-python-package-gower/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gower\n",
    "# we compute this distance explained above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extension to custom distance matrix :\n",
    "- if it's a numeric or a categorical feature, use Gower distance\n",
    "- if it's a list, use Jaccard distance.\n",
    "\n",
    "Here we are going to use Jaccard distance to measure distance of the brute genres and brutes topics. We also calculate Jaccard distance for a vector of the selected genres.\n",
    "[Jaccard distance](https://flavien-vidal.medium.com/similarity-distances-for-natural-language-processing-16f63cd5ba55) is defined for a subset A and B (here represented by a list) by :\n",
    "\n",
    "$d_J(A,B) = 1 - J(A,B)$ where $J(A,B)$ is the Jaccard index defined by :\n",
    "\n",
    "$J(A,B) = card(A \\cap B) / card(A \\cup B)$ = proportion of common points\n",
    "\n",
    "The code is inspired by this [Statology post](https://www.statology.org/jaccard-similarity-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Jaccard Similarity function\n",
    "def jaccard(list1, list2):\n",
    "    if len(list1+list2) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        intersection = len(list(set(list1).intersection(list2)))\n",
    "        union = (len(list1) + len(list2)) - intersection\n",
    "        return float(intersection) / union       \n",
    "def jaccard_dissimilarity_matrix(df):\n",
    "    n = len(df)\n",
    "    matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j  in range(i):\n",
    "            d = 1 - jaccard(df.iloc[i],df.iloc[j])\n",
    "            matrix[i,j] = d\n",
    "            matrix[j,i] = d\n",
    "    return matrix\n",
    "\n",
    "def custom_distance_matrix(df_clustering):\n",
    "    \"\"\"the idea is to do an extension of the gower distance with the defined custom distance\n",
    "    since the final distance matrix is the mean of each dissimilarity matrix we will use the distance matrix to compute for \n",
    "    numerical and categorical and compute our own matrix to compute for list var\"\"\"\n",
    "    distance_matrix = gower.gower_matrix(df_clustering[numvar+categorical_var])\n",
    "    distance_matrix = len(numvar+categorical_var)*distance_matrix\n",
    "    for var in list_var:\n",
    "        distance_matrix += jaccard_dissimilarity_matrix(df_clustering[var])\n",
    "    distance_matrix = distance_matrix/len(numvar+categorical_var+list_var)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = custom_distance_matrix(df_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(distance_matrix<0).any() or (distance_matrix>1).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With clustering DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "dbscan_cluster = DBSCAN(eps=0.11, \n",
    "                    min_samples=2, \n",
    "                    metric=\"precomputed\")\n",
    "q, mod = divmod(j, 2)\n",
    "'''\n",
    "Create SilhouetteVisualizer instance with KMeans instance\n",
    "Fit the visualizer\n",
    "'''\n",
    "visualizer = SilhouetteVisualizer(dbscan_cluster, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "ax[q-1][mod].set_title(\"k = \" + str(i))\n",
    "dbscan_cluster.fit(distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering[\"cluster\"] = dbscan_cluster.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters :\n",
    "\n",
    "(-1 = outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of song by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-1, df_clustering['cluster'].nunique()):\n",
    "    print(len(df_clustering[df_clustering['cluster']==i]), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly a failure : the first cluster is too big, which is coherent, DBScan is made for outliers spotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AffinityPropagation\n",
    "Trying with another clustering methods : AffinityPropagation. Results are corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.cluster import SpectralClustering essayé fonctionne très mal\n",
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples : we can set a series of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_id = ['6z4n862KhNJNWDYSn4aLL5','7uv632EkfwYhXoqf8rhYrg','1GMQEnykhAyTLwkIViTFQk','16tvIGzCNfRLVbm8G39DDo',\n",
    "'5mY8mY7DSfuqVbY2psq3Cg','6jkN2vp6rSP1WMlPJVlWQB','6TSDRzJGwbK9cajVbtqlPV','56iv5TqfvxVa4zLMs6SvmP','0cx1vZcndRhwSDgR8NtEfk',\n",
    "'4h33lJL2YU05kEMaSkao47','7Fe3ZwOjTVppElF4TMfxNP','46WOptLnXUtH3LOyYvmMO1','4Ztvl8C9Ld3IdHNo1a3UBe','5N7NLLGdrTy4QYuyM6ewm0','2Y0iGXY6m6immVb2ktbseM',\n",
    "'3gcmn2CtOE9SjBevmvGVEk','2mcMoXYHmVLxmCgAvaO2cS','3XZssUmtDdhFK1tZJasgXD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(examples_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_index = list(df_playlist.loc[df_playlist['id'].isin(examples_id)].index)\n",
    "preferences = np.zeros(len(df_clustering))\n",
    "for i in examples_index:\n",
    "    preferences[i]=1/len(examples_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosen_model = KMeans(n_clusters=10, init='k-means++', n_init=10, max_iter=2000, random_state=100)# 200,42\n",
    "choosen_model = AffinityPropagation(damping = 0.5, affinity='precomputed', max_iter=1000,preference=preferences)\n",
    "# idée assigné des points au musique en fonction de mon nombre d'écoute => voir la doc dans preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = choosen_model.fit(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering['cluster'] = results.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of clusters : (and in the idea the number of playlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many songs by playlist :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"For the cluster {i}, there are {len(df_clustering[df_clustering['cluster']==i])} songs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of characteristics has each cluster : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering.groupby('cluster').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see for each cluster what is the central track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_playlist.iloc[results.cluster_centers_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_playlist = df_clustering['cluster'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"U2FsdGVkX1/Dr36Htbd0NHeSyt7zcwtOQAlJhOZtI448GRilIUDqUXbG2VcrJ3P9vptgDzKVDtdT4Oem\n",
    "8or4aSpWtATxKVoPB0zFaiDwvO9xGZ3LMmczFu4VdpSm41KwAVd47tUU3rB6GYnBfBbLgglun0vTKlp0\n",
    "EkSa+Nf8A3paQIcCKVIjvQFD4jUyIdqucqh+De+Q83QfBXsawCoByXTbVrMeA+KClO6eFO5yvh8cc0GS\n",
    "Xa/ulwOiGLIZR94ZatZNG4HHOHdPnFlJ5VS48olv0FzUV9tXom/9omdtF+Qm2nragQ30nfMQUG4q56Dl\n",
    "D2bCxpM7LHcqUeyt8rtDCGKvLKm3Op17OJ3mgCDQpRpXFc+fqJCyKXhEglMOJ4g2gox4xvBtCVtPlKsp\n",
    "9HLO2GKPXO9GsFGmYlGtVkMm1ZqfAR90tWZvfYWNUBI5ZlffvB9VGmsRi4zoM+LyETIhJtEtPOUG0NVO\n",
    "/I1pVHy20yGBZC4/szf8/NUnbf0Njelz4gc6oppflk2fDeZn5pr5Zl38rL81G/Ev2gmm476UXdE=\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary with authorization keys\n",
    "CREDENTIALS = {}\n",
    "CREDENTIALS['client_id'] = client_id\n",
    "CREDENTIALS['client_secret'] = client_secret\n",
    "CREDENTIALS['redirect_url'] = redirect_url\n",
    "CREDENTIALS['user_id'] = userid\n",
    "CREDENTIALS['genius_access_token'] = genius_access_token # genius is optional, only\n",
    "\n",
    "\"\"\"You also can set your credentials id on credentials.py and import from spotiscience\"\"\"\n",
    "\n",
    "# returns 'downloader class'\n",
    "sd = sps.downloader.SpotiScienceDownloader(credentials=CREDENTIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sps.downloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = sps.downloader.SpotiScienceDownloader(credentials=CREDENTIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_playlist):\n",
    "    song_ids =[]\n",
    "    for id in df_playlist[df_clustering['cluster']==i]['id']:\n",
    "        song_ids.append(\"spotify:track:\"+id)\n",
    "    sd.add_playlist(f\"AffinityPropagation Cluster V3 {i}\",song_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idée d'amélioration possible mettre moins de poids à certaines choses en faisant moi même la moyenne "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('spotify')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:33) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "799d35822260b865e0047a7cbeabbac3935807c2e6d2340d94cf57d360182bae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
